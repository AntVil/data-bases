{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "- data lake\n",
    "  - raw data\n",
    "  - easy access\n",
    "  - great for data science\n",
    "  - no defined purpose (yet)\n",
    "  - processing/conversion only done once data is needed\n",
    "- data warehouse\n",
    "  - processed clean/high-quality data\n",
    "  - harder to make changes\n",
    "- lazy evaluation for saving resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "# operation\n",
    "\n",
    "seconds_taken = (datetime.datetime.now() - start).total_seconds()\n",
    "print(f\"{seconds_taken}s\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# key-value-store\n",
    "- key can be any string\n",
    "- value can be any string\n",
    "- update not directly possible (requires: read, update, write)\n",
    "- great for caching\n",
    "\n",
    "### Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "\n",
    "# setup client\n",
    "r = redis.Redis(host=\"127.0.0.1\", port=6379, db=0)\n",
    "\n",
    "\n",
    "# set value\n",
    "r.set(\"key\", \"value\")\n",
    "\n",
    "# get value (common python encodings: \"ascii\", \"utf-8\", \"latin1\")\n",
    "value = r.get(\"key\").decode(\"utf-8\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### publish subscribe in redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "\n",
    "# setup publish\n",
    "pub = redis.Redis(host=\"localhost\", port=6379, db=0)\n",
    "\n",
    "\n",
    "# setup subscribe\n",
    "sub_redis = redis.Redis(host=\"localhost\", port=6379, db=0)\n",
    "sub = sub_redis.pubsub()\n",
    "sub.subscribe(\"sub_list\")\n",
    "\n",
    "\n",
    "# publish content\n",
    "pub.publish(\"sub_list\", \"message\")\n",
    "\n",
    "# get subscribe message\n",
    "print(sub.get_message())\n",
    "\n",
    "# get content message\n",
    "print(sub.get_message())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# document-database\n",
    "- key can be any string\n",
    "- value has to be a document\n",
    "- searching and other operations possible on documents\n",
    "- great for semi-structured data\n",
    "\n",
    "### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "\n",
    "\n",
    "# setup client\n",
    "m = pymongo.MongoClient(\"127.0.0.1\", 27017)\n",
    "\n",
    "# select/create database\n",
    "db = m[\"database\"]\n",
    "\n",
    "# select/create collection in database\n",
    "c = db[\"collection\"]\n",
    "\n",
    "\n",
    "# set value\n",
    "c.insert_one({\"key1\": \"value1\", \"key2\": \"value2\"})\n",
    "\n",
    "# get value with condition key1 = value1\n",
    "c.find_one({\"key1\": \"value1\"})\n",
    "\n",
    "# get values with condition key1 = value1 (returns an iterator)\n",
    "c.find({\"key1\": \"value1\"})\n",
    "\n",
    "\n",
    "# aggregations/pipelines\n",
    "pipeline=[\n",
    "    {\n",
    "        \"$match\": { \"key\": re.compile(\"regex\") }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$key\",\n",
    "            \"count\": { \"$sum\": 1 }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": { \"count\": pymongo.ASCENDING }\n",
    "    }\n",
    "]\n",
    "\n",
    "# get value after applying pipeline (returns an iterator)\n",
    "c.aggregate(pipeline)\n",
    "\n",
    "# additional aggregations:\n",
    "# { \"$match\": { \"key\": { \"$gt\": 100 } } }\n",
    "# { \"$count\": \"key\" }\n",
    "# { \"$sortByCount\": \"$key\" }\n",
    "# { \"$out\": { \"db\": \"database\", \"coll\": \"collection\" } }\n",
    "\n",
    "\n",
    "# get distinct keys\n",
    "c.distinct(\"key1\")\n",
    "\n",
    "# make update\n",
    "c.update_one(\n",
    "    { \"key1\": \"value1\" },\n",
    "    { \"$set\": { \"key2\": \"value2\" }}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "\n",
    "# setup spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "# read text file as dataframe (column=\"value\" each line in seperate row)\n",
    "df = spark.read.text(\"text_file.txt\")\n",
    "\n",
    "# read csv file as dataframe infering types & reading first line as colum-headers (for tsv: sep=\"\\t\")\n",
    "df = spark.read.csv(\"comma_seperated_values.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# split into words using java regex (every string of uninterrupted letters is considered a word)\n",
    "df = df.select(split(df.value, \"[^A-Za-z]+\").alias(\"value\"))\n",
    "\n",
    "# flatten all arrays in each row (rows with empty arrays result in empty rows)\n",
    "df = df.select(explode(df.value).alias(\"value\"))\n",
    "\n",
    "# remove empty rows\n",
    "df = df.filter(df.value != \"\")\n",
    "\n",
    "\n",
    "# print results (force evaluation of previous calls)\n",
    "df.show()\n",
    "\n",
    "# conversion to pandas\n",
    "df.toPandas()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb33305f22ea6bf664d50db0ca8b776af2d2e6f359410588206cfe81ad080bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
